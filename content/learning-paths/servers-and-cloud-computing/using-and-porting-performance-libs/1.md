---
title: Introduction to Performance Libraries
weight: 2

### FIXED, DO NOT MODIFY
layout: learningpathall
---

# Introduction to Performance Libraries

The C++ Standard Library provides a collection of classes and functions that are essential for everyday programming tasks, such as data structures, algorithms, and input/output operations. It is designed to be versatile and easy to use, ensuring compatibility and portability across different platforms. However, as a result of this portability, standard libraries introduce some limitations. Performance sensitive applications may wish to take maximum advantage of the hardware's capabilities - this is where performance libraries come in. 

Performance libraries are tailored to high-performance computing tasks and are often designed for the microarchitecture of a specific processor. These libraries are optimized for speed and efficiency, often leveraging hardware-specific features such as vector units to achieve maximum performance. Performance libraries are crafted through extensive benchmarking and optimization, and can be domain specific, such as genomics libraries, or produced by Arm for general-purpose computing. For example, OpenRNG focuses on generating random numbers quickly and efficiently, which is crucial for simulations and scientific computations, whereas the C++ Standard Library offers a more general-purpose approach with functions like `std::mt19937` for random number generation.

Performance libraries for Arm CPUs, such as the Arm Performance Libraries (APL), provide highly optimized mathematical functions for scientific computing. An analogous library for accelerating routines on a GPU is cuBLAS for NVIDIA GPUs. These libraries can be linked dynamically at runtime or statically during compilation, offering flexibility in deployment. They are designed to support multiple versions of the Arm architecture, including those with Neon and SVE.  Generally, minimal source code changes are required to use these libraries, making them suitable for porting and optimizing applications. 

## How Can I Choose the Right Version of a Performance Library?

Performance libraries are often distributed with multiple formats to support various use cases. 

- **ILP64** uses 64 bits for representing integers, which are often used for indexing large arrays in scientific computing. In C++ source code we use the `long long` type to specify 64-bit integers; 

- **LP64** uses 32 bits to present integers which are more common in general-purpose applications; and 

- **Open Multi-Process** (OpenMP) is a programming interface for paralleling workloads across many CPU cores and multiple platforms (i.e. x86, AArch64 etc.). Programmers interact primarily through compiler directives, such as `#pragma omp parallel` indicating which section of source code can be run in parallel and which sections require synchronization. 

Like the x86 equivalent, Open Math Kernel Library (MKL), APL provide optimized functions for both ILP64 and LP64 as well as OpenMP or single threaded implementations. Further, the interface libraries are available as shared libraries for dynamic linking (i.e. `*.so`) or static linking (i.e. `*.a`).

## Why Do Multiple Performance Libraries Exist?

A natural source of confusion stems from the plethora of similar seeming performance libraries. For example, OpenBLAS and NVIDIA Performance Libraries (NVPL) both have their own implementations for basic linear algebra subprograms (BLAS). This begs the question which one should a developer use?

Multiple performance libraries coexist to cater to the diverse needs of different hardware architectures and applications. For example, APL are optimized for Arm CPUs, leveraging their unique instruction sets and power efficiency. On the other hand, NVPL for Grace CPUs are tailored to maximize the performance of NVIDIA's hardware.

- **Hardware Specialization**  Some libraries are designed to be cross-platform, supporting multiple hardware architectures to provide flexibility and broader usability. For example, the OpenBLAS library supports both Arm and x86 architectures, allowing developers to use the same library across different systems; 

- **Domain-Specific Libraries**: Libraries are often created to handle specific domains or types of computations more efficiently. For instance, libraries like cuDNN are optimized for deep learning tasks, providing specialized functions that significantly speed up neural network training and inference; and

- **Commercial Libraries**: Alternatively, some highly performant libraries require a license to use. This is more common in domain-specific libraries such as computational chemistry or fluid dynamics. 

These factors contribute to the existence of multiple performance libraries, each tailored to meet the specific demands of various hardware and applications.

Invariably, there will be performance differences between each library and the best way to observe them is to use the library within your own application. 

For more information on performance benchmarking you can read [Arm Performance Libraries 24.10](https://community.arm.com/arm-community-blogs/b/servers-and-cloud-computing-blog/posts/arm-performance-libraries-24-10).

### What Performance Libraries Are Available on Arm?

For a directory of community-produced libraries we recommend looking at the the Software Ecosystem Dashboard for Arm. Each library may not be available as a binary and may need to be compiled from source. The table below gives examples of libraries that are available on Arm. 

| Package / Library    | Domain |
| -------- | ------- |
| Minimap2  | Long-read sequence alignment in genomics    |
| HMMER |Bioinformatics library for homologous sequences     |
| FFTW    | Open-source fast fourier transform library    |

See the [Software Ecosystem Dashboard for Arm](https://www.arm.com/developer-hub/ecosystem-dashboard) for the most comprehensive and up-to-date list.