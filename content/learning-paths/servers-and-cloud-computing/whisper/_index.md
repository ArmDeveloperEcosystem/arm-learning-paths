---
title: Accelerate Whisper on Arm with Hugging Face Transformers

minutes_to_complete: 15

who_is_this_for: This Learning Path is for software developers familiar with basic machine learning concepts and looking to run the OpenAI Whisper Automatic Speech Recognition (ASR) model efficiently, using an Arm-based cloud instance.

learning_objectives:
    - Install the dependencies for the Whisper ASR Model.
    - Run the Whisper model using Hugging Face Transformers.
    - Enable performance-enhancing features for running the model on Arm CPUs.
    - Evaluate transcript generation times using Whisper.


prerequisites:
    - An [Arm-based compute instance](/learning-paths/servers-and-cloud-computing/intro/) running Ubuntu with 32 cores, 8GB of RAM, and 32GB of disk space.
    - Basic knowledge of Python.
    - Familiarity with machine learning concepts.
    - Familiarity with the fundamentals of the Whisper ASR Model.

author: Nobel Chowdary Mandepudi

### Tags
skilllevels: Introductory
armips:
    - Neoverse
subjects: ML
cloud_service_providers:
  - AWS
  - Microsoft Azure
  - Google Cloud
  - Oracle
operatingsystems:
    - Linux
tools_software_languages:
    - Python
    - Whisper
    - Demo
    - Hugging Face

    

further_reading:
    - resource:
        title: Hugging Face Transformers documentation
        link: https://huggingface.co/transformers/v4.11.3/index.html
        type: documentation


### FIXED, DO NOT MODIFY
# ================================================================================
weight: 1                       # _index.md always has weight of 1 to order correctly
layout: "learningpathall"       # All files under learning paths have this same wrapper
learning_path_main_page: "yes"  # This should be surfaced when looking for related content. Only set for _index.md of learning path content.
---
