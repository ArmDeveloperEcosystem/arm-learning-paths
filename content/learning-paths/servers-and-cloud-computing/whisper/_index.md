---
title: Accelerate OpenAI Whisper on Arm with Hugging Face Transformers

minutes_to_complete: 15

who_is_this_for: This Learning Path is for software developers looking to run the Whisper Automatic Speech Recognition (ASR) model efficiently. You will use an Arm-based cloud instance to run and build speech transcription based applications.

learning_objectives:
    - Install the dependencies to run the Whisper Model.
    - Run the OpenAI Whisper model using Hugging Face Transformers.
    - Enable performance-enhancing features for running the model on Arm CPUs.
    - Compare the total time taken to generate transcript with Whisper.


prerequisites:
    - An [Arm-based compute instance](/learning-paths/servers-and-cloud-computing/intro/) with 32 cores, 8GB of RAM, and 32GB disk space running Ubuntu.
    - Basic understanding of Python and ML concepts.
    - Understanding of Whisper ASR Model fundamentals.

author: Nobel Chowdary Mandepudi

### Tags
skilllevels: Introductory
armips:
    - Neoverse
subjects: ML
operatingsystems:
    - Linux
tools_software_languages:
    - Python
    - Whisper
cloud_service_providers: AWS
    

further_reading:
    - resource:
        title: Hugging Face Transformers documentation
        link: https://huggingface.co/transformers/v4.11.3/index.html
        type: documentation


### FIXED, DO NOT MODIFY
# ================================================================================
weight: 1                       # _index.md always has weight of 1 to order correctly
layout: "learningpathall"       # All files under learning paths have this same wrapper
learning_path_main_page: "yes"  # This should be surfaced when looking for related content. Only set for _index.md of learning path content.
---
