---
title: Run an AI Agent Application with llama.cpp and llama-cpp-agent using KleidiAI on Arm servers.

draft: true
cascade:
    draft: true

minutes_to_complete: 45

who_is_this_for: This is an introductory topic for software developers and ML engineers looking to run an AI Agent Application.

learning_objectives:
    - Set up llama-cpp-python optimised for Arm servers.
    - Learn how to run optimized LLM models.
    - Learn how to create custom functions for LLMs.
    - Learn how to use AI Agents for applications.

prerequisites:
    - An [Arm-based instance](/learning-paths/servers-and-cloud-computing/csp/) from a cloud service provider or an on-premise Arm server.
    - Basic understanding of Python and Prompt Engineering
    - Understanding of LLM fundamentals.

author: Andrew Choi

### Tags
skilllevels: Introductory
subjects: ML
armips:
    - Neoverse
tools_software_languages:
    - Python
    - AWS Graviton
operatingsystems:
    - Linux



further_reading:
    - resource:
        title: llama.cpp
        link: https://github.com/ggml-org/llama.cpp
        type: documentation
    - resource:
        title: llama-cpp-agent
        link: https://llama-cpp-agent.readthedocs.io/en/latest/
        type: documentation



### FIXED, DO NOT MODIFY
# ================================================================================
weight: 1                       # _index.md always has weight of 1 to order correctly
layout: "learningpathall"       # All files under learning paths have this same wrapper
learning_path_main_page: "yes"  # This should be surfaced when looking for related content. Only set for _index.md of learning path content.
---
